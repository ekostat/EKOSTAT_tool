{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "D:\\Utveckling\\git\\ekostat_calculator\n"
     ]
    }
   ],
   "source": [
    "# Reload when code changed:\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pwd\n",
    "import sys\n",
    "import os\n",
    "path = \"../\"\n",
    "sys.path.append(path)\n",
    "#os.path.abspath(\"../\")\n",
    "print(os.path.abspath(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..\\core\\__init__.py\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0.19.2'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "import core\n",
    "import importlib\n",
    "importlib.reload(core) \n",
    "try:\n",
    "    logging.shutdown()\n",
    "    importlib.reload(logging)\n",
    "except:\n",
    "    pass\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "\n",
    "from event_handler import EventHandler\n",
    "print(core.__file__)\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "print(time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integrated_mean(depth_list, \n",
    "                        value_list, \n",
    "                        depth_interval):\n",
    "    \n",
    "    depth_list = list(depth_list)\n",
    "    value_list = list(value_list)\n",
    "    sum_list = []\n",
    "    # Make sure to integrate the whole surface layer if selected\n",
    "    if depth_list[0] != depth_interval[0]:\n",
    "        depth_list.insert(0, depth_interval[0])\n",
    "        value_list.insert(0, value_list[0])\n",
    "    if depth_list[-1] != depth_interval[-1]:\n",
    "        depth_list.append(depth_interval[-1])\n",
    "        value_list.append(value_list[-1])\n",
    "\n",
    "    for z0, z1, v0, v1 in zip(depth_list[:-1], depth_list[1:], \n",
    "                              value_list[:-1], value_list[1:]):\n",
    "\n",
    "        part_sum = 0.5*(v1+v0)*(z1-z0)\n",
    "\n",
    "        sum_list.append(part_sum)\n",
    "\n",
    "    return sum(sum_list)/(depth_list[-1]-depth_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_integrated_mean_alt(depth_list, \n",
    "                        value_list, \n",
    "                        depth_interval):\n",
    "    \n",
    "    sum_list = []\n",
    "    # Make sure to integrate the whole surface layer if selected\n",
    "    if depth_list[0] != depth_interval[0]:\n",
    "        depth_list = np.insert(depth_list, depth_interval[0])\n",
    "        value_list = np.insert(value_list, value_list[0])\n",
    "    if depth_list[-1] != depth_interval[-1]:\n",
    "        depth_list = np.append(depth_list, depth_interval[-1])\n",
    "        value_list = np.append(value_list, value_list[-1])\n",
    "    \n",
    "    sum_list = np.sum(0.5*(value_list[1:]+value_list[:-1])*(depth_list[1:]-depth_list[:-1]))\n",
    "\n",
    "    return sum_list/(depth_list[-1]-depth_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7720022201538086\n",
      "1.2730119228363037\n",
      "361666.666666\n",
      "361666.666666\n"
     ]
    }
   ],
   "source": [
    "nr = 100000\n",
    "\n",
    "depth_list = np.array([0, 5, 10, 15])\n",
    "value_list = np.array([1.2, 4.3, 5.3, 1.3]) \n",
    "depth_interval = np.array([0, 5, 10, 15])\n",
    "\n",
    "t0 = time.time()\n",
    "list_1 = []\n",
    "for k in range(nr): \n",
    "    list_1.append(get_integrated_mean(depth_list, \n",
    "                                      value_list, \n",
    "                                      depth_interval))\n",
    "print(time.time() - t0) \n",
    "\n",
    "t0 = time.time()\n",
    "list_2 = []\n",
    "for k in range(nr): \n",
    "    list_2.append(get_integrated_mean_alt(depth_list, \n",
    "                                          value_list, \n",
    "                                          depth_interval))\n",
    "print(time.time() - t0)\n",
    "\n",
    "print(sum(list_1))\n",
    "print(sum(list_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exclude_index_array(df): \n",
    "    exclude_list = []\n",
    "    for col in df.columns:\n",
    "        if 'Q_' in col:\n",
    "            exclude_list.append(col[2:])\n",
    "            exclude_list.append(col)\n",
    "            \n",
    "    exclude_index_list = [True if par in exclude_list else False for par in df.columns]\n",
    "    return np.array(exclude_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(df):\n",
    "    \n",
    "    if len(df) < min_nr_values:\n",
    "        #print(len(df))\n",
    "        return False\n",
    "    # Extrac data lists\n",
    "    depth_list = list(df['DEPH'].values) \n",
    "    value_list = list(df[use_par].values) \n",
    "    \n",
    "    t_calc_integ = time.time()\n",
    "    mean_value = get_integrated_mean(depth_list, \n",
    "                                     value_list, \n",
    "                                     depth_interval)\n",
    "    time_list_calc_integ.append(time.time() - t_calc_integ)\n",
    "    \n",
    "    t_add_row = time.time()\n",
    "    # Add info to row\n",
    "    new_row_series = df.loc[df.index[0], :].copy(deep=True)\n",
    "    new_row_series[new_par] = mean_value\n",
    "    new_row_series[new_par_depths] = ';'.join(map(str, depth_list))\n",
    "    new_row_series[new_par_values] = ';'.join(map(str, value_list))\n",
    "    new_row_series['MNDEP'] = depth_interval[0]\n",
    "    new_row_series['MXDEP'] = depth_interval[1]\n",
    "    #print('df.columns', len(df.columns))\n",
    "    #print(df.columns)\n",
    "    new_row = np.array(new_row_series)\n",
    "    new_row[exclude_index_array] = np.nan\n",
    "\n",
    "    new_list_to_append.append(list(new_row)) \n",
    "    time_list_add_row.append(time.time() - t_add_row)\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_par = 'CPHL_BTL'\n",
    "new_par = 'CHPL_INTEG_CALC' \n",
    "new_par_depths = new_par + '_depths'\n",
    "new_par_values = new_par + '_values' \n",
    "depth_interval = [0, 10]\n",
    "min_nr_values = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Total time: 4.082029819488525\n",
      "time_preparations              0.010000228881835938\n",
      "time_list_group_data:          0.039999961853027344\n",
      "time_list_calc_integ:          0.014999866485595703\n",
      "time_list_add_row:             1.553013801574707\n",
      "time_all_calculations:         4.032029628753662\n",
      "time_iterator:                 0.0\n"
     ]
    }
   ],
   "source": [
    "all_data = pd.read_csv('all_data.txt', sep='\\t', encoding='cp1252') \n",
    "\n",
    "new_list_to_append = [] # list of lists with the new rows to be added to all_data once all calculations are done\n",
    "# new_df = pd.DataFrame(columns=all_data.columns)\n",
    "\n",
    "time_list_group_data = []\n",
    "time_list_calc_integ = []\n",
    "time_list_add_row = [] \n",
    "\n",
    "\n",
    "\n",
    "t_tot = time.time()\n",
    "t_preparations = time.time()\n",
    "# Add result columns\n",
    "all_data[new_par] = np.nan \n",
    "all_data[new_par_depths] = np.nan\n",
    "all_data[new_par_values] = np.nan\n",
    "# Temp \n",
    "all_data['MNDEP'] = np.nan\n",
    "all_data['MXDEP'] = np.nan\n",
    "\n",
    "\n",
    "exclude_index_array = get_exclude_index_array(all_data) \n",
    "# print(len(exclude_index_array))\n",
    "# print(len(all_data.columns))\n",
    "\n",
    "# Narrow the data to only include lines where par is present and depth is in range\n",
    "use_par_boolean = ~all_data[use_par].isnull() \n",
    "depth_boolean = (all_data['DEPH'] >= depth_interval[0]) & \\\n",
    "                (all_data['DEPH'] <= depth_interval[1]) \n",
    "    \n",
    "active_boolean = use_par_boolean & depth_boolean\n",
    "time_preparations = time.time() - t_preparations\n",
    "\n",
    "\n",
    "t_group_data = time.time()\n",
    "grouped_data = all_data.loc[active_boolean, :].groupby('visit_id_str')\n",
    "time_list_group_data.append(time.time() - t_group_data)\n",
    "\n",
    "t_iterator = time.time()\n",
    "calculations = (calculate(group) for visit_id, group in grouped_data)\n",
    "time_iterator = time.time() - t_iterator\n",
    "\n",
    "t_all_calculation = time.time()\n",
    "result = list(calculations)\n",
    "time_all_calculation = time.time() - t_all_calculation\n",
    "time_total = time.time() - t_tot\n",
    "\n",
    "print('-'*50)\n",
    "print('Total time:', time_total)\n",
    "print('time_preparations'.ljust(30), time_preparations)\n",
    "print('time_list_group_data:'.ljust(30), sum(time_list_group_data))\n",
    "print('time_list_calc_integ:'.ljust(30), sum(time_list_calc_integ))\n",
    "print('time_list_add_row:'.ljust(30), sum(time_list_add_row)) \n",
    "print('time_all_calculations:'.ljust(30), time_all_calculation)\n",
    "print('time_iterator:'.ljust(30), time_iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3260"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_list_to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MYEAR</th>\n",
       "      <th>SDATE</th>\n",
       "      <th>STIME</th>\n",
       "      <th>SHIPC</th>\n",
       "      <th>SERNO</th>\n",
       "      <th>STATN</th>\n",
       "      <th>LATIT_DD</th>\n",
       "      <th>LONGI_DD</th>\n",
       "      <th>VISS_EU_CD</th>\n",
       "      <th>WATER_BODY_NAME</th>\n",
       "      <th>...</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>Q_TEMP</th>\n",
       "      <th>source_TEMP</th>\n",
       "      <th>DOXY</th>\n",
       "      <th>Q_DOXY</th>\n",
       "      <th>source_DOXY</th>\n",
       "      <th>index_column</th>\n",
       "      <th>CHPL_INTEG_CALC</th>\n",
       "      <th>CHPL_INTEG_CALC_depths</th>\n",
       "      <th>CHPL_INTEG_CALC_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MYEAR, SDATE, STIME, SHIPC, SERNO, STATN, LATIT_DD, LONGI_DD, VISS_EU_CD, WATER_BODY_NAME, SEA_BASIN, WATER_DISTRICT, WATER_TYPE_AREA, WLTYP, DEPH, TEMP_BTL, Q_TEMP_BTL, TEMP_CTD, Q_TEMP_CTD, SALT_BTL, Q_SALT_BTL, SALT_CTD, Q_SALT_CTD, DOXY_BTL, Q_DOXY_BTL, DOXY_CTD, Q_DOXY_CTD, PHOS, Q_PHOS, NTRI, Q_NTRI, NTRA, Q_NTRA, NTRZ, Q_NTRZ, AMON, Q_AMON, CPHL_BTL, Q_CPHL_BTL, SECCHI, Q_SECCHI, NTOT, Q_NTOT, PTOT, Q_PTOT, origin_dtype, origin_file_path, DIN, MONTH, YEAR, visit_id_str, SALT, Q_SALT, source_SALT, TEMP, Q_TEMP, source_TEMP, DOXY, Q_DOXY, source_DOXY, index_column, CHPL_INTEG_CALC, CHPL_INTEG_CALC_depths, CHPL_INTEG_CALC_values]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 64 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(columns=all_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1,2,3,4])\n",
    "i = np.array([False, True, True, False])\n",
    "list(a[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.loc[all_data['DEPH']==10, :].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2017, '2017-12-06', '07:30', '77SN', 164, 'BYTTELOCKET',\n",
       "       58.353669999999994, 11.24, 'SE582147-111771',\n",
       "       'Kungshamn s skärgård', 'Skagerrak', 'Västerhavets vattendistrikt',\n",
       "       '01n - Västkustens inre kustvatten', '2 - Havsområde innanför 1 NM',\n",
       "       0.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, 'PhysicalChemical',\n",
       "       'sharkweb_data_fyskem_wb_2007-2017_20180320.txt',\n",
       "       4.6799999999999997, 12, 2017, '58.3536711.240002017-12-0607:30',\n",
       "       nan, nan, 'SALT_CTD', nan, nan, 'TEMP_BTL', nan, nan, 'DOXY_BTL', 0,\n",
       "       nan, nan, nan], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.array(all_data.loc[all_data.index[0], :])\n",
    "d[get_exclude_index_array(all_data)] = np.nan\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypsograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.mapping import Hypsograph \n",
    "\n",
    "file_path = 'D:/Utveckling/git/ekostat_calculator/resources/mappings/hypsografs_2017.txt'\n",
    "h = Hypsograph(file_path)\n",
    "wb = 'NO591045-111030'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.6299999999999999"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_total_area_of_water_body(wb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0050860719874804387"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.get_volume_fraction_below_depth(wb, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Continuum\\Anaconda3\\envs\\EKOSTAT_tool\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (22,23,25,26,28,29,30,31,32,33,34,35,37,38,45,61,62,64,65,67,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "101465"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('all_data.txt', encoding='cp1252', sep='\\t') \n",
    "exclude_qf=['B', 'S']\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "5         False\n",
       "6         False\n",
       "7         False\n",
       "8         False\n",
       "9         False\n",
       "10        False\n",
       "11        False\n",
       "12        False\n",
       "13        False\n",
       "14        False\n",
       "15        False\n",
       "16        False\n",
       "17        False\n",
       "18        False\n",
       "19        False\n",
       "20        False\n",
       "21        False\n",
       "22        False\n",
       "23        False\n",
       "24        False\n",
       "25        False\n",
       "26        False\n",
       "27        False\n",
       "28        False\n",
       "29        False\n",
       "          ...  \n",
       "101435    False\n",
       "101436    False\n",
       "101437    False\n",
       "101438    False\n",
       "101439    False\n",
       "101440    False\n",
       "101441    False\n",
       "101442    False\n",
       "101443    False\n",
       "101444    False\n",
       "101445    False\n",
       "101446    False\n",
       "101447    False\n",
       "101448    False\n",
       "101449    False\n",
       "101450    False\n",
       "101451    False\n",
       "101452    False\n",
       "101453    False\n",
       "101454    False\n",
       "101455    False\n",
       "101456    False\n",
       "101457    False\n",
       "101458    False\n",
       "101459    False\n",
       "101460    False\n",
       "101461    False\n",
       "101462    False\n",
       "101463    False\n",
       "101464    False\n",
       "Name: DEPH, dtype: bool"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['DEPH'] >= depth_interval[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9679\n",
      "9674\n"
     ]
    }
   ],
   "source": [
    "cphl_boolean = ~df['CPHL_BTL'].isnull() \n",
    "len(np.where(cphl_boolean)[0])\n",
    "unique_visit_id_list = list(set(df.loc[cphl_boolean, 'visit_id_str']))\n",
    "print(len(unique_visit_id_list))\n",
    "\n",
    "\n",
    "depth_interval = [0, 10]\n",
    "depth_boolean = (df['DEPH'] >= depth_interval[0]) & \\\n",
    "                        (df['DEPH'] <= depth_interval[1])\n",
    "unique_visit_id_list = list(set(df.loc[cphl_boolean & depth_boolean, 'visit_id_str']))    \n",
    "print(len(unique_visit_id_list))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  8.]\n",
      "[ 1.3  3.2]\n",
      "2.44\n",
      "[70638.0, 70638.0, nan, nan, nan, 1.3, nan, 0.0, 0.16, nan, nan, 58.7405, 11.24483, 0, 10, 2009.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, '2009-06-09', 'Skagerrak', nan, 645.0, nan, '7798', 'SANNÄSFJORDEN', '07:40', nan, nan, 'SE584450-111445', 'Sannäsfjorden sek namn', 'Västerhavets vattendistrikt', '01n - Västkustens inre kustvatten', '2 - Havsområde innanför 1 NM', 'PhysicalChemical', 'sharkweb_data_fyskem_wb_2007-2017_20180320.txt', 6.0, 2009.0, nan, nan, nan, nan, nan, nan, nan, nan, nan, '58.7405011.244832009-06-0907:40', 2.4399999999999999, '0.0;8.0', '1.3;3.2']\n",
      "101466\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                         70638\n",
       "Unnamed: 0.1                                                       70638\n",
       "AMON                                                                 NaN\n",
       "BIOV_CONC_ALL                                                        NaN\n",
       "BQIm                                                                 NaN\n",
       "CPHL_BTL                                                             1.3\n",
       "CPHL_INTEG                                                           NaN\n",
       "DEPH                                                                   0\n",
       "DIN                                                                 0.16\n",
       "DOXY_BTL                                                             NaN\n",
       "DOXY_CTD                                                             NaN\n",
       "LATIT_DD                                                         58.7405\n",
       "LONGI_DD                                                         11.2448\n",
       "MNDEP                                                                  0\n",
       "MXDEP                                                                 10\n",
       "MYEAR                                                               2009\n",
       "NTOT                                                                 NaN\n",
       "NTRA                                                                 NaN\n",
       "NTRI                                                                 NaN\n",
       "NTRZ                                                                 NaN\n",
       "PHOS                                                                 NaN\n",
       "PTOT                                                                 NaN\n",
       "Q_AMON                                                               NaN\n",
       "Q_BIOV_CONC_ALL                                                      NaN\n",
       "Q_BQIm                                                               NaN\n",
       "Q_CPHL_INTEG                                                         NaN\n",
       "Q_DOXY_BTL                                                           NaN\n",
       "Q_DOXY_CTD                                                           NaN\n",
       "Q_NTOT                                                               NaN\n",
       "Q_NTRA                                                               NaN\n",
       "                                               ...                      \n",
       "SECCHI                                                               NaN\n",
       "SERNO                                                                645\n",
       "SHARKID_MD5                                                          NaN\n",
       "SHIPC                                                               7798\n",
       "STATN                                                      SANNÄSFJORDEN\n",
       "STIME                                                              07:40\n",
       "TEMP_BTL                                                             NaN\n",
       "TEMP_CTD                                                             NaN\n",
       "VISS_EU_CD                                               SE584450-111445\n",
       "WATER_BODY_NAME                                   Sannäsfjorden sek namn\n",
       "WATER_DISTRICT                               Västerhavets vattendistrikt\n",
       "WATER_TYPE_AREA                        01n - Västkustens inre kustvatten\n",
       "WLTYP                                       2 - Havsområde innanför 1 NM\n",
       "origin_dtype                                            PhysicalChemical\n",
       "origin_file_path          sharkweb_data_fyskem_wb_2007-2017_20180320.txt\n",
       "MONTH                                                                  6\n",
       "YEAR                                                                2009\n",
       "SALT                                                                 NaN\n",
       "Q_SALT                                                               NaN\n",
       "source_SALT                                                          NaN\n",
       "TEMP                                                                 NaN\n",
       "Q_TEMP                                                               NaN\n",
       "source_TEMP                                                          NaN\n",
       "DOXY                                                                 NaN\n",
       "Q_DOXY                                                               NaN\n",
       "source_DOXY                                                          NaN\n",
       "visit_id_str                             58.7405011.244832009-06-0907:40\n",
       "CHPL_INTEG_CALC                                                     2.44\n",
       "CHPL_INTEG_CALC_depths                                           0.0;8.0\n",
       "CHPL_INTEG_CALC_values                                           1.3;3.2\n",
       "Name: 101467, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CHPL_INTEG_CALC'] = np.nan \n",
    "df['CHPL_INTEG_CALC_depths'] = np.nan\n",
    "df['CHPL_INTEG_CALC_values'] = np.nan\n",
    "\n",
    "len(unique_visit_id_list)\n",
    "current_visit_id = unique_visit_id_list[1000]\n",
    "current_visit_id\n",
    "visit_boolean = df['visit_id_str'] == current_visit_id\n",
    "\n",
    "par = 'CPHL_BTL'\n",
    "depth_interval = [0, 10]\n",
    "min_nr_values = 2\n",
    "\n",
    "depths = df.loc[visit_boolean & cphl_boolean, 'DEPH'].values \n",
    "values = df.loc[visit_boolean & cphl_boolean, par].values \n",
    "\n",
    "index = np.where((depths >= depth_interval[0]) & (depths <= depth_interval[-1]))[0]\n",
    "depth_list = depths[index]\n",
    "value_list = values[index]\n",
    "\n",
    "print(depth_list)\n",
    "print(value_list)\n",
    "\n",
    "mean_value = get_integrated_mean(depth_list, \n",
    "                                 value_list, \n",
    "                                 depth_interval)\n",
    "            \n",
    "print(mean_value)\n",
    "\n",
    "if mean_value:\n",
    "    exclude_list = [] \n",
    "    for item in df.columns: \n",
    "        if item.startswith('Q_'):\n",
    "            exclude_list.append(item[2:])\n",
    "            exclude_list.append(item)\n",
    "        elif item.startswith('source_'): \n",
    "            exclude_list.append(item)\n",
    "\n",
    "\n",
    "    new_row = [] \n",
    "    for par, value in zip(df.columns, df.loc[visit_boolean,:].values[0]):\n",
    "        if par == 'MNDEP': \n",
    "            new_row.append(depth_interval[0])\n",
    "        elif par == 'MXDEP': \n",
    "            new_row.append(depth_interval[1])\n",
    "        elif par == 'CPHL_INTEG_CALC': \n",
    "            new_row.append(mean_value)\n",
    "        elif par == 'CPHL_INTEG_CALC_depths': \n",
    "            new_row.append(';'.join(map(str, depth_list)))\n",
    "        elif par == 'CPHL_INTEG_CALC_values': \n",
    "            new_row.append(';'.join(map(str, value_list)))\n",
    "        elif par in exclude_list: \n",
    "            new_row.append(np.nan)\n",
    "        else:\n",
    "            new_row.append(value)\n",
    "\n",
    "    print(new_row)\n",
    "\n",
    "max_df_index = max(df.index)\n",
    "print(max_df_index)\n",
    "df.loc[max_df_index+1, :] = new_row\n",
    "df.loc[max(df.index), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=101465, step=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['Unnamed: 0', 'Unnamed: 0.1']]\n",
    "df.set_index('Unnamed: 0')\n",
    "# df.head()\n",
    "# df.columns\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16048, 16048, 0.7, nan, nan, 0.1, nan, 0.5, 0.98, 8.03, nan,\n",
       "       55.385830000000006, 13.643, nan, nan, 2015, 15.7, 0.21, 0.07, nan,\n",
       "       0.48, 0.61, '<', nan, nan, nan, nan, nan, nan, '<', '<', nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, 8.04, '2015-05-06',\n",
       "       'Arkonahavet och S Öresund', 11.9, 389.0, nan, '7798', 'ABBEKÅS',\n",
       "       '08:35', nan, 8.0, 'SE552170-130626', 'Ö sydkustens kustvatten',\n",
       "       'Södra Östersjöns vattendistrikt', '07 - Skånes kustvatten',\n",
       "       '2 - Havsområde innanför 1 NM', 'PhysicalChemical',\n",
       "       'sharkweb_data_fyskem_wb_2007-2017_20180320.txt', 5, 2015, 8.04,\n",
       "       nan, 'SALT_CTD', 8.0, nan, 'TEMP_CTD', 8.03, nan, 'DOXY_BTL',\n",
       "       '55.3858313.643002015-05-0608:35'], dtype=object)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[visit_boolean,:].values[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.5   5.   10. ]\n",
      "[ 0.1  0.2  0.3]\n"
     ]
    }
   ],
   "source": [
    "print(depths)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_1 = df['visit_id_str'] == '55.3858313.643002015-05-0608:35'\n",
    "bool_2.loc[len(df)+1] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101468\n",
      "101469\n"
     ]
    }
   ],
   "source": [
    "print(len(bool_1))\n",
    "print(len(bool_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101459     True\n",
       "101460     True\n",
       "101461     True\n",
       "101462     True\n",
       "101463     True\n",
       "101464     True\n",
       "101465     True\n",
       "101466     True\n",
       "101467     True\n",
       "101469    False\n",
       "Name: visit_id_str, dtype: bool"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_3 = bool_1 & bool_2\n",
    "len(bool_3)\n",
    "bool_3[len(bool_3)-10: len(bool_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,1,0,0], dtype=bool)\n",
    "b = np.array([1,1,0,0, 1], dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,) (5,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-c5273c79eea7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m&\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,) (5,) "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
